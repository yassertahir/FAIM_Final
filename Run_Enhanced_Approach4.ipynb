{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf19c08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Run the Enhanced Approach 4 for IPO valuation prediction\n",
    "This notebook executes the enhanced model that uses ALL non-IPO funding rounds for training\n",
    "instead of just the latest round per company.\n",
    "\"\"\"\n",
    "\n",
    "# Import the enhanced approach implementation\n",
    "import sys\n",
    "sys.path.append('/home/yasir/Downloads/codes/FAIM_Final/')\n",
    "\n",
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "from Enhanced_Approach4 import enhance_approach4\n",
    "\n",
    "# Set larger figure size for better visualizations\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "\n",
    "# Ignore specific warnings during execution\n",
    "warnings.filterwarnings('ignore', category=RuntimeWarning)\n",
    "\n",
    "# Run the enhanced approach with error handling\n",
    "try:\n",
    "    print(\"Starting the Enhanced Approach 4 implementation...\")\n",
    "    result = enhance_approach4()\n",
    "    if isinstance(result, tuple):\n",
    "        model, model_info = result\n",
    "    else:\n",
    "        # If we got back just the ensemble results\n",
    "        model_info = result\n",
    "        model = None\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()\n",
    "    model, model_info = None, None\n",
    "\n",
    "# If model was successfully trained, analyze performance\n",
    "if model_info is not None:\n",
    "    print(\"\\n\\nAnalysis of Enhanced Approach 4 Results:\")\n",
    "    print(\"=======================================\")\n",
    "    \n",
    "    # Highlight the key differences and benefits\n",
    "    print(\"\\nKey advantages of Enhanced Approach 4:\")\n",
    "    print(\"----------------------------------\")\n",
    "    print(\"1. Uses ALL non-IPO funding rounds for training (not just the latest round)\")\n",
    "    print(\"2. Incorporates robust outlier handling techniques\")\n",
    "    print(\"3. Uses both mean and median-based error metrics for better performance evaluation\")\n",
    "    print(\"4. Employs robust scaling for better handling of extreme values\")\n",
    "    print(\"5. Includes additional features for handling early-to-IPO valuation jumps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e44575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a comparative analysis between approaches if model was successful\n",
    "if model_info is not None:\n",
    "    try:\n",
    "        # Load the Enhanced Approach 3 results for comparison\n",
    "        # This assumes you've run Enhanced Approach 3 and saved the results\n",
    "        import pickle\n",
    "        import os\n",
    "        \n",
    "        # Check if we have saved results from Enhanced Approach 3\n",
    "        ea3_model_path = \"enhanced_approach3_best_model.pkl\"\n",
    "        \n",
    "        if os.path.exists(ea3_model_path):\n",
    "            with open(ea3_model_path, \"rb\") as f:\n",
    "                ea3_model = pickle.load(f)\n",
    "            print(\"Successfully loaded Enhanced Approach 3 model for comparison\")\n",
    "            \n",
    "            # Compare the two approaches\n",
    "            print(\"\\nComparison between Enhanced Approach 3 and Enhanced Approach 4:\")\n",
    "            print(\"-----------------------------------------------------------\")\n",
    "            print(\"Enhanced Approach 3: Uses latest non-IPO round for each company\")\n",
    "            print(\"Enhanced Approach 4: Uses ALL non-IPO rounds to train the model\")\n",
    "            \n",
    "            # If you have performance metrics saved, you can compare them here\n",
    "            # For example: print(f\"Approach 3 MAPE: {ea3_mape:.2f}% vs Approach 4 MAPE: {ea4_mape:.2f}%\")\n",
    "        else:\n",
    "            print(\"Could not find saved results for Enhanced Approach 3 for comparison\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"Error in comparison: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08234bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualizations to better understand the model performance\n",
    "if model_info is not None:\n",
    "    try:\n",
    "        # Import required components - these are available after running enhance_approach4()\n",
    "        from Enhanced_Approach4 import enhance_approach4\n",
    "        import pandas as pd\n",
    "        \n",
    "        # Create visualizations based on available data\n",
    "        # We need to reconstruct the necessary variables to create the plots\n",
    "        \n",
    "        try:\n",
    "            # Get the data and relevant variables \n",
    "            df = pd.read_csv('combined_ipo_with_urls.csv')\n",
    "            target_variable = 'Post Valuation'\n",
    "            \n",
    "            # Try to get IPO vs non-IPO data\n",
    "            if 'Deal Type' in df.columns:\n",
    "                # Create a mask for IPO entries\n",
    "                ipo_mask = df['Deal Type'] == \"IPO\"\n",
    "                ipo_data = df[ipo_mask].copy()\n",
    "                \n",
    "                # If model_info contains predictions, use those\n",
    "                if isinstance(model_info, dict) and 'Ensemble' in model_info and 'Predictions' in model_info['Ensemble']:\n",
    "                    y_pred = model_info['Ensemble']['Predictions']\n",
    "                    y_test = np.log1p(ipo_data[target_variable])\n",
    "                    y_true = np.expm1(y_test)\n",
    "                    \n",
    "                    # Create a scatter plot with log scale for better visualization\n",
    "                    plt.subplot(2, 2, 1)\n",
    "                    plt.scatter(y_true, y_pred, alpha=0.6)\n",
    "                    plt.plot([0, y_true.max()], [0, y_true.max()], 'r--')\n",
    "                    plt.xscale('log')\n",
    "                    plt.yscale('log')\n",
    "                    plt.title('Actual vs. Predicted IPO Valuations (log scale)')\n",
    "                    plt.xlabel('Actual Valuation ($)')\n",
    "                    plt.ylabel('Predicted Valuation ($)')\n",
    "                    plt.grid(True, alpha=0.3)\n",
    "                    \n",
    "                    # Error distribution histogram\n",
    "                    plt.subplot(2, 2, 2)\n",
    "                    valid_indices = np.isfinite(y_true) & np.isfinite(y_pred) & (y_true != 0)\n",
    "                    percentage_errors = np.abs((y_true[valid_indices] - y_pred[valid_indices]) / y_true[valid_indices]) * 100\n",
    "                    plt.hist(percentage_errors, bins=20, color='skyblue', edgecolor='black')\n",
    "                    plt.axvline(percentage_errors.mean(), color='red', linestyle='--', \n",
    "                              label=f'Mean: {percentage_errors.mean():.2f}%')\n",
    "                    plt.axvline(np.median(percentage_errors), color='green', linestyle='--', \n",
    "                              label=f'Median: {np.median(percentage_errors):.2f}%')\n",
    "                    plt.title('Distribution of Percentage Errors')\n",
    "                    plt.xlabel('Absolute Percentage Error (%)')\n",
    "                    plt.ylabel('Frequency')\n",
    "                    plt.legend()\n",
    "                    plt.grid(True, alpha=0.3)\n",
    "                    \n",
    "                    # Summary statistics\n",
    "                    print(f\"Performance Summary:\")\n",
    "                    print(f\"Mean Absolute Percentage Error (MAPE): {percentage_errors.mean():.2f}%\")\n",
    "                    print(f\"Median Absolute Percentage Error (MdAPE): {np.median(percentage_errors):.2f}%\")\n",
    "                    print(f\"Number of IPO valuations predicted: {len(y_pred)}\")\n",
    "                \n",
    "                else:\n",
    "                    plt.subplot(1, 1, 1)\n",
    "                    plt.text(0.5, 0.5, \"Cannot create detailed visualizations - prediction data not available\", \n",
    "                           ha='center', va='center', fontsize=14, color='red')\n",
    "                    plt.axis('off')\n",
    "            \n",
    "            else:\n",
    "                plt.subplot(1, 1, 1)\n",
    "                plt.text(0.5, 0.5, \"Cannot create visualizations - 'Deal Type' column not found in data\",\n",
    "                       ha='center', va='center', fontsize=14, color='red')\n",
    "                plt.axis('off')\n",
    "                \n",
    "        except Exception as e:\n",
    "            plt.figure(figsize=(10, 5))\n",
    "            plt.text(0.5, 0.5, f\"Error creating visualizations: {str(e)}\", \n",
    "                   ha='center', va='center', fontsize=14, color='red')\n",
    "            plt.axis('off')\n",
    "            print(f\"Error creating visualizations: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('enhanced_approach4_analysis.png', dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error creating visualizations: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8d33652",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the Enhanced Approach 4 best model for future use\n",
    "if model is not None:\n",
    "    try:\n",
    "        import pickle\n",
    "        \n",
    "        # Save the final model\n",
    "        with open(\"enhanced_approach4_best_model.pkl\", \"wb\") as f:\n",
    "            pickle.dump(model, f)\n",
    "        print(\"Successfully saved Enhanced Approach 4 best model\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error saving model: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62c4353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create documentation for Enhanced Approach 4\n",
    "\"\"\"\n",
    "# Enhanced Approach 4 Documentation\n",
    "\n",
    "## Overview\n",
    "\n",
    "Enhanced Approach 4 builds on the foundation of Enhanced Approach 3 but makes a critical change in the \n",
    "data splitting strategy:\n",
    "\n",
    "- **Enhanced Approach 3**: Uses only the latest non-IPO funding round for each company to train the model.\n",
    "- **Enhanced Approach 4**: Uses ALL non-IPO funding rounds for model training.\n",
    "\n",
    "## Key Advantages\n",
    "\n",
    "1. **Larger Training Dataset**: By utilizing all non-IPO rounds instead of just the latest round, \n",
    "   the model has access to 2-3x more training data.\n",
    "   \n",
    "2. **Better Learning of Round Progression**: The model can learn patterns of valuation changes \n",
    "   across different funding rounds.\n",
    "   \n",
    "3. **Improved Outlier Handling**: \n",
    "   - Uses `RobustScaler` instead of `StandardScaler`\n",
    "   - Implements custom `OutlierClipper` transformer\n",
    "   - Includes `HuberRegressor` which is less affected by outliers\n",
    "   \n",
    "4. **More Robust Metrics**:\n",
    "   - Added Median Absolute Percentage Error (MdAPE)\n",
    "   - Added Median Absolute Error (MedAE)\n",
    "   - Both are less influenced by extreme values than mean-based metrics\n",
    "\n",
    "5. **Additional Features**:\n",
    "   - Round sequence numbering\n",
    "   - Company funding round progression speed\n",
    "   - Outlier indicators for extreme valuations\n",
    "\n",
    "## Implementation Details\n",
    "\n",
    "```python\n",
    "# Key difference in data splitting strategy\n",
    "# Define train and test sets - ALL non-IPO goes to train, ALL IPO goes to test\n",
    "X_train = X[~ipo_mask].drop(columns=[target_variable])\n",
    "y_train = y_log[~ipo_mask]\n",
    "X_test = X[ipo_mask].drop(columns=[target_variable])\n",
    "y_test = y_log[ipo_mask]\n",
    "```\n",
    "\n",
    "## Performance Metrics\n",
    "\n",
    "The model's performance is evaluated using multiple metrics to get a comprehensive view:\n",
    "\n",
    "1. **MAE (Mean Absolute Error)**: Average absolute difference between predictions and actual values\n",
    "2. **RMSE (Root Mean Squared Error)**: Square root of the average squared differences\n",
    "3. **R² Score**: Proportion of variance in the target variable explained by the model\n",
    "4. **MAPE (Mean Absolute Percentage Error)**: Average percentage difference\n",
    "5. **MdAPE (Median Absolute Percentage Error)**: Median percentage difference, more robust to outliers\n",
    "6. **Median AE**: Median absolute error, less sensitive to extreme values\n",
    "\n",
    "## Comparison to Previous Approaches\n",
    "\n",
    "| Approach | Key Strategy | Training Data Size | Primary Advantage |\n",
    "|----------|-------------|-------------------|------------------|\n",
    "| Approach 1 | All non-IPO rounds → All IPO rounds | Large | Maximizes training data |\n",
    "| Approach 2 | IPO-only with 75-25 split | Small | Focuses on most relevant data |\n",
    "| Approach 3 | Latest non-IPO round → IPO round | Medium | Better company matching |\n",
    "| Enhanced Approach 3 | Latest non-IPO round + new features → IPO round | Medium | Handles valuation jumps |\n",
    "| Enhanced Approach 4 | **ALL non-IPO rounds + new features → IPO round** | **Large** | **Maximizes data + handles jumps** |\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
